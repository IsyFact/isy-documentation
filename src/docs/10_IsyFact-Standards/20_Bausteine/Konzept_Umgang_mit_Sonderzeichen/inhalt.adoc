[[ueberblick]]
= Überblick

[[anforderungen-und-randbedingungen]]
== Anforderungen und Randbedingungen

An die Verarbeitung von Sonderzeichen nach IsyFact-Standards bestehen die folgenden Anforderungen:

* Prinzipiell (technisch) muss jedes Sonderzeichen nutzbar sein.
* Jedes System nach IsyFact-Standards muss die Sonderzeichen in gleicher Weise verarbeiten können.
* Nach Erlass des BMI ist für das Personenstands,- Melde- und Ausländerwesen die Verarbeitung sämtlicher Zeichen gem.
<<XOEVStringLatin>> vorgegeben.
Weder mehr noch weniger Zeichen darf/muss das System verarbeiten können.

[[festlegung-des-zeichensatzes-und-der-codierung]]
== Festlegung des Zeichensatzes und der Codierung

Im SAGA-Standard 4.0 <<SAGA40>> wird der Zeichensatz Unicode v4.x (ISO 10646:2003) in der UTF-8-Codierung als
obligatorisch aufgeführt.
Das BMI hat als Rahmenbedingung für seinen Verantwortungsbereich auf der Basis des SAGA-Standards festgelegt,
für die Zeichencodierung in neuen Systemen ausschließlich UTF-8 zu nutzen.
Dieser Zeichensatz stellt ausreichend viele der weltweit existierenden Buchstaben, Ziffern und Symbole zur
Verfügung, um Daten in internationalen Schreibweisen abbilden zu können.

Gemäß den Anforderungen des String-latin Zeichensatzes des BMI <<XOEVStringLatin>> soll die IsyFact genau diesen
Zeichensatz unterstützen.
Daher wird festgelegt, dass für IsyFact-Standard-basierte Anwendungen der Zeichensatz Unicode v4.x in der
UTF-8-Codierung zu verwenden ist.

[[konfigurationseinstellungen-für-den-zeichensatz]]
= Konfigurationseinstellungen für den Zeichensatz

Im Folgenden wird die Konfiguration der technischen Systeme zur Verwendung des Zeichensatzes erläutert.
Um zu erreichen, dass jedes IsyFact-konforme System Sonderzeichen in gleicher Weise verarbeitet,
wird durchgängig Unicode v4.x in der UTF-8-Codierung verwendet.

[[betriebssystem]]
== Betriebssystem

Die Standard-Zeichencodierung aller in der Plattform verwendeten Betriebssysteme muss einheitlich auf die
Verwendung von Unicode v4.x in der UTF-8-Codierung gesetzt werden.

Als Beispiel wird hier das Betriebssystem SUSE Linux Enterprise Server (SLES) 10 betrachtet.
Hier ist die Standard-Zeichencodierung UTF-8. Diese kann über den Konfigurationsparameter

`LC_CTYPE = UTF8`

auch für jeden Benutzer individuell gesetzt werden.

[[oracle-datenbank]]
== Oracle Datenbank

Die Zeichencodierung aller in der Plattform verwendeten Datenbanken muss ebenfalls einheitlich auf die Verwendung
von Unicode v4.x in der UTF-8-Codierung gesetzt werden.

Als Beispiel wird hier die Datenbank Oracle 11g betrachtet.
Oracle unterstützt ab Version 10g Release 2 Unicode v4.0. Oracle empfiehlt <<DGSG>>, neue Datenbanken als
Unicode-Datenbanken anzulegen.
Hierzu muss beim CREATE DATABASE die folgende Eigenschaft gesetzt werden:

`CHARACTER SET AL32UTF8`

[[hibernate]]
== Hibernate

Für Hibernate werden der Unicode-Zeichensatz und die UTF-Zeichencodierung über die beiden Parameter

`hibernate.connection.useUnicode = true`

und

`hibernate.connection.characterEncoding = utf-8`

konfiguriert.
Im Kontext der IsyFact-Standards wird Hibernate nicht direkt, sondern über JPA und Spring genutzt.
Hierzu sind diese Einstellungen in der entsprechenden Konfigurationsdatei `jpa.xml` unter den Properties des Entity
Managers wie folgt abzulegen:

[source,xml]
----
<property
    <bean id="entityManagerFactory" class="org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean">
  <property name="jpaProperties">
    <props>
      …
      <prop key="hibernate.connection.useUnicode">true</prop>
      <prop key="hibernate.connection.characterEncoding">utf-8</prop>
  </property>

</bean>
----

In Eclipse ist an mehreren Stellen die Zeichencodierung zu setzen.
Das erfolgt über den Preferences-Dialog von Eclipse, der über die Menüleiste aufgerufen wird (`Window - Preferences...`).
Folgende Einstellungen sind zu machen:

[source,text]
----
General -> Workspace: Text file encoding - Other = UTF-8
Web and XML -> CSS Files: Encoding = ISO 10646/Unicode(UTF-8)
Web and XML -> HTML Files: Encoding = ISO 10646/Unicode(UTF-8)
Web and XML -> JSP Files: Encoding = ISO 10646/Unicode(UTF-8)
Web and XML -> XML Files: Encoding = ISO 10646/Unicode(UTF-8)
----

WARNING: Diese Einstellungen sind Workspace-spezifisch, d.h. sie müssen für jeden Workspace individuell eingestellt werden.

[[java]]
== Java

Im Java-Compiler wird die Zeichencodierung der Quelldateien beim Aufruf über den Parameter

`–encoding UTF-8`

gesetzt.
In der JVM wird die Standard-Zeichencodierung beim Aufruf über den Parameter

`-Dfile.encoding=UTF-8`

gesetzt.

[[java-property-dateien]]
== Java Property-Dateien

Bis zur Java-Version 1.5 werden Property-Dateien grundsätzlich ISO 8859-1 codiert gelesen und geschrieben.
Das ist unabhängig von den Einstellungen des Zeichensatzes in der JVM und im Betriebssystem.
Das Tool native2ascii (Native-to-ASCII Converter,
siehe http://docs.oracle.com/javase/1.5.0/docs/tooldocs/windows/native2ascii.html) kann für die Umcodierung von Property-Dateien verwendet werden.

Bei XML-basierten Property-Dateien, können auch andere Zeichencodierungen verwendet werden.

[[maven]]
== Maven

Der Build erfolgt mit Maven. Hier ist die Zeichencodierung wie folgt zu setzen:

[source, xml]
----
<project>
...
  <build>
    <plugins>
      <plugin>
        <groupId>org.apache.maven.plugins</groupId>
        <artifactId>maven-resources-plugin</artifactId>
...
        <configuration>
          <encoding>UTF-8</encoding>
        </configuration>
      </plugin>
...
      <plugin>
        <artifactId>maven-compiler-plugin</artifactId>
        <configuration>
...
          <compilerArguments>
            <encoding>UTF-8</encoding>
...
          </compilerArguments>
        </configuration>
      </plugin>
...
    </plugins>
...
  </build>
...
  <reporting>
    <plugin>
      <groupId>org.apache.maven.plugins</groupId>
      <artifactId>maven-javadoc-plugin</artifactId>
...
        <configuration>
          <encoding>UTF-8</encoding>
        </configuration>
    </plugin>
...
  </reporting>
...
</project>
----

[[xml]]
== XML

UTF-8 ist die Standard-Zeichencodierung für XML.
Das wird in der ersten Zeile der XML-Datei wie folgt deklariert:

`<?xml version="1.0" **encoding="UTF-8"**?>`

[[html]]
== HTML

In HTML wird die Zeichencodierung in den Metadaten des HEAD-Tags wie folgt angegeben:

[source,html]
----
<meta http-equiv="Content-Type"
    content="text/html; charset=utf-8" />
----

Damit dürfen auch keine HTML-Sonderzeichen mehr verwendet werden, sondern nur noch UTF-8-codierte Zeichen.

[[transformation-von-sonderzeichen]]
= Transformation von Sonderzeichen

In den Fällen, wo kein Unicode-Zeichensatz verwendet werden kann, müssen Sonderzeichen eventuell in andere
Darstellungen oder Codierungen umgewandelt werden.
Hierzu gibt es prinzipiell drei Möglichkeiten: die Transkription, die Umcodierung und das Filtern von Zeichen.
In diesem Kapitel werden diese drei Möglichkeiten in je einem Unterkapitel beschrieben.

[[transkription]]
== Transkription

Transkription (Umschreibung) ist eine aussprachebasierte Darstellung eines fremden Alphabetes mit dem eigenen Alphabet,
also z.B. die Darstellung russischer Namen in kyrillischer Schreibweise mit dem deutschen Alphabet.
Transkription wird eingesetzt, um ohne Kenntnisse einer fremdem Sprache und des zugehörigen Alphabets eine halbwegs
richtige Aussprache von Wörtern zu ermöglichen.
Eine eindeutige Rückübertragung ist in der Regel nicht möglich.
Im Folgenden werden die Festlegungen zur Transkription im Rahmen der IsyFact-Standards beschrieben.

[[zeichensaetze-und-sprachen]]
=== Zeichensätze und Sprachen

Wie in Kapitel <<festlegung-des-zeichensatzes-und-der-codierung>> festgelegt, wird für die IsyFact der Zeichensatz
Unicode v4.x in der UTF-8-Codierung verwendet.
Die Transkription überführt die internationalen Sonderzeichen aus dem Unicode v4.x Zeichensatz in den ASCII-Zeichensatz.

Im Rahmen der IsyFact werden zur Zeit von der Transkription nur kyrillische, griechische und lateinische Zeichen
 unterstützt, da hiermit die im europäischen Raum gebräuchlichen Zeichen abgedeckt sind.

[[anwendungsbereiche-in-einer-isyfact-systemlandschaft]]
=== Anwendungsbereiche in einer IsyFact-Systemlandschaft

Transkription ist an den folgenden Stellen von Bedeutung:

*Datenaustausch mit anderen Systemen*::
Für nach IsyFact-Standards entwickelte Anwendungen ist der zu verwendende Zeichensatz festgelegt.
Andere Systeme, mit denen diese kommunizieren, können aber einen anderen Zeichensatz verwenden.
Hier müssen die Daten zunächst in den Zeichensatz des Zielsystems umgewandelt werden.
Die Umwandlung kann durch Transkription geschehen.
 +
[underline]#Beispiel:# Ein Nachbarsystem arbeitet ausschließlich mit dem ASCII-Zeichensatz.
Daten einer Anwendung nach IsyFact-Standards werden zunächst umgeschrieben und dann dem Nachbarsystem übergeben.

*Einheitliche Repräsentation von Daten*::
Für Namen können verschiedene ländertypische Schreibweisen genutzt werden.
Trotzdem sollen Daten aber vergleichbar sein.
Hier kann die Transkription zu einer einheitlichen (normierten) Schreibweise führen.
Werden dann Suchen auf den umgeschriebenen Daten durchgeführt, erhöht sich die Wahrscheinlichkeit, dass der
Gesuchte in der Trefferliste ist.
Dadurch verbessert sich aber nicht unbedingt die Trefferqualität.
 +
[underline]#Beispiel:# „Müller“ wird im Originalschreibweise gespeichert und für die Suche zu „Mueller“ umgeschrieben.
Eine Suchanfrage nach „Müller“ wird zunächst zu „Mueller“ umgeschrieben, dann gesucht und auch gefunden.
Eine Suchanfrage nach „Mueller“ braucht nicht umgeschrieben werden und wird gefunden.

Transkription wird in der Regel nur für Namen verwendet, also für Vornamen, Nachnamen und Ortsbezeichnungen.

[[transkriptionsregeln]]
=== Transkriptionsregeln

Die Transkription basiert auf dem ICAO-Standard (ICAO-MRTD). Der ICAO-Standard wurde ursprünglich für das
automatische Lesen von Dokumenten in der Luftfahrt entwickelt.
Er umfasst 142 Abbildungsvorschriften (Regeln) für lateinische und kyrillische Buchstaben.
Für die Abbildung von griechischen Zeichen wird der Standard ISO-843 verwendet.

Während der ISO-Standard (ISO-9) für die Transkription von kyrillischen Zeichen noch diakritische lateinische
Zeichen verwendet, ist bei ICAO-MRTD das Ziel, diakritische Zeichen vollständig zu vermeiden, um eine Abbildung
auf den ASCII-Zeichensatz zu ermöglichen.
Eine bereits umgeschriebene Zeichenfolge wird durch eine erneute Transkription nicht mehr verändert.

In <<table-transkription>> sind die Transkriptionsregeln für die verschiedenen Zeichen dargestellt.

[[umsetzung-im-system]]
=== Umsetzung im System

Daten werden immer im Originalformat gespeichert.
Umgeschriebene Daten können bei Bedarf zusätzlich abgelegt werden.
Dabei sind die der Transkription zugrunde liegenden Parameter ebenfalls mit abzulegen.
Dies führt zu folgendem Datentyp für umgeschriebene Zeichenfolgen:

:desc-image-001: Datentyp für umgeschriebene Texte
[id="image-001",reftext="{figure-caption} {counter:figures}"]
.{desc-image-001}
image::sonderzeichen_001.png[pdfwidth=35%,width=35%,align="center"]

Die Attribute für den Datentyp „TransText“ haben die folgende Bedeutung:

:desc-table-TransTextAttribute: Attribute des Datentyps „TransText“
[id="table-TransTextAttribute",reftext="{table-caption} {counter:tables}"]
.{desc-table-TransTextAttribute}
[cols="2,1,3",options="header"]
|====
|Attribut |optional |Beschreibung
|`original` |nein |Originaltext im Unicode-Zeichenformat
|`sprache` |ja |Sprachcode gemäß ISO 639 für die Sprache des Originaltextes
|`transkription` |nein |umgeschriebener Text
|`methode` |nein |Kennzeichen für den bei der Transkription verwendeten Satz von Transkriptionsregeln, also der
Methode nach der die Transkription durchgeführt wurde.
Verschiedene Versionen der gleichen Transkriptionsregeln können durch eigene Kennzeichen abgebildet werden.
|====


Die Transkription soll nicht als zentraler Dienst sondern als Komponente umgesetzt werden, die bei Bedarf in die
Anwendungen eingebunden wird.
Dabei sind die Transkriptionsregeln in einer oder mehreren Konfigurationsdateien hinterlegt, die von der Komponente
eingelesen werden.
Darüber wird auch eine einfache Erweiterbarkeit der Transkriptionsregeln gewährleistet.
Es ist möglich, mehrere Sätze von Transkriptionsregeln zu hinterlegen, um so auch andere Standards für die Transkription
verwenden zu können.

:desc-image-002: Komponente Transkription
[id="image-002",reftext="{figure-caption} {counter:figures}"]
.{desc-image-002}
image::sonderzeichen_002.png[pdfwidth=50%,width=50%,align="center"]


Die Komponente Transkription bietet nach außen nur die Methode

[source,java]
----
TransText umschreiben(String text, String sprache, String methode)
----

an. Hier ist der Parameter `text` der umzuschreibende Text, `sprache` der Sprachcode gemäß ISO 639 und `methode` das
Kennzeichen des zu verwendenden Satzes von Transkriptionsregeln.
Ergebnis ist die umgeschriebene Darstellung des Textes gemäß dem Datentyp `TransText`.
Im Fehlerfall werden entsprechende Exceptions geworfen.
Die Angabe der Sprache ist optional.
Ist die Sprache unbekannt, d.h. es wird kein Sprachcode übergeben, dann wird die Sprache bei der Transkription nicht
berücksichtigt.

[[umcodierung]]
== Umcodierung

Textdaten, die von der Anwendung aus einer Datei eingelesen werden oder über eine Programm-Schnittstelle übergeben
werden, können eventuell nicht in UTF-8 codiert sein.

Textdateien werden in der Standard-Zeichencodierung der JVM eingelesen und gespeichert (siehe auch Kapitel <<java>>).
Sollte eine andere Zeichencodierung verwendet werden, so muss dies explizit im Code umgesetzt werden.

Das kann z.B. erfolgen, indem die Dateien mit einem `InputStreamReader` gelesen werden bzw.
mit einem `OutputStreamWriter` geschrieben werden.
In beiden Klassen kann im Konstruktor der Zeichensatz angegeben werden.
Beim Lesen werden die Daten dann automatisch decodiert bzw.
beim Schreiben codiert.

Dieses Verfahren kann für beliebige Byte-Arrays verwendet werden, so dass auch Daten, die über eine Programm-Schnittstelle
übergeben werden, so umcodiert werden können.

[[filtern-von-zeichen]]
== Filtern von Zeichen

Neben den druckbaren Zeichen enthält der Unicode-Zeichensatz auch nicht druckbare Steuerzeichen (Ugs. „Schmierzeichen“).
Diese Zeichen können an der Oberfläche bei der Übernahme aus anderen Programmen über die Zwischenablage oder beim
Import von Daten in eine IsyFact-konforme Anwendung gelangen.
Diese Zeichen sind prinzipiell bei der Validierung der Daten auszufiltern.
Ob der Benutzer von diesem Vorgang informiert wird oder ob Log-Einträge geschrieben werden, hängt von der
Fachlichkeit der jeweiligen Anwendung ab.
Je nach Anwendung kann es auch sinnvoll sein, einige Steuerzeichen, wie z.B. einen Zeilenumbruch, zuzulassen.
Diese von der Anwendung abhängigen Festlegungen müssen in der Spezifikation bzw.
im Systementwurf der jeweiligen Anwendung beschrieben werden.

[[spezifikation-von-fachlichen-datentypen]]
== Spezifikation von fachlichen Datentypen

Bereits in der Spezifikation ist darauf zu achten, dass für einen fachlichen Datentyp die zulässigen Zeichen
genau angegeben werden.
Nur so können die entsprechenden Validierungen konzipiert und umgesetzt werden.
Hier ist der Datentyp String bzw.
Alpha in der Regel zu grob.
Hier müssen abgestufte Typen für Textinhalte definiert werden, z.B. Alpha-Latein-Basis (alle großen und kleinen
lateinischen Buchstaben ohne diakritische Zeichen), Alpha-Latein-Diakrit (alle großen und kleinen lateinischen Buchstaben inklusiv diakritische Zeichen), Alpha-Europa (alle großen und kleinen lateinischen, griechischen und kyrillischen Zeichen, inklusiv diakritischer Zeichen).

[[bibliothek-isy-sonderzeichen]]
= Bibliothek „isy-sonderzeichen“

Dieses Kapitel beschreibt die Verwendung des Bausteins `isy-sonderzeichen`.

Der Baustein `isy-sonderzeichen` ist eine Querschnittskomponente, die anderen Anwendungen Services zur
Transformation von Zeichenketten zur Verfügung stellt. Die Bibliothek stellt dabei eine feste Anzahl von Transformatoren zur Verfügung, die für eine einheitliche
Transformation von Zeichenketten innerhalb der Systemumgebung sorgen.

Im Zuge der Umsetzung der DIN Spezifikation 91 379 wurde `isy-sonderzeichen` erweitert. Um die ursprüngliche Funktionalität zu erhalten,
wurde die Bibliothek in zwei Packages aufgeteilt. Das _stringlatin1_1_ Package enthält die ursprüngliche Funktionalität. Die Umsetzung der
DIN Spezifikation wurde im Package _dinspec91379_ umgesetzt. Die Architektur und Funktionsweise der Komponente wurde im Zuge der
Umsetzung nicht verändert.

[[funktionsweise]]
== Funktionsweise

Die Transformatoren arbeiten alle nach dem gleichen Schema.
Sie unterscheiden sich nur durch unterschiedliche Tabellen, die zur Zeichentransformation herangezogen werden.

. Alle Zeichen werden gemäß einer Mapping-Tabelle transformiert (Beispiel in <<table-transkription>>).
. Unbekannte oder nicht abbildbare Zeichen werden durch Leerzeichen ersetzt.
. Leerzeichen am Anfang und am Ende der Zeichenkette werden entfernt.
. Zwei aufeinanderfolgende Leerzeichen werden durch ein einzelnes Leerzeichen ersetzt.

Transformatoren müssen in der Regel projektspezifisch entwickelt werden.
Darüber hinaus werden folgende Transformatoren mitgeliefert:

*Identischer Transformator*

Dieser Transformator bildet alle gültigen String.Latin-Zeichen auf sich selber ab. Der
Nutzen dieses Transformators liegt darin, dass alle nicht String.Latin-Zeichen aus der übergebenen Zeichenkette entfernt werden.
Dieser Transformator ermöglicht keine Vorgabe der maximalen Zeichenlänge.

*Transkription Transformator*

Dieser Transformator führt die in <<table-transkription>> dargestellte Transkription durch. Die Transkription ist eine aussprachebasierte
Darstellung der übergebenen Zeichenkette, die mit dem ASCII-Zeichensatz dargestellt werden kann.
Dieser Transformator ermöglicht keine Vorgabe der maximalen Zeichenlänge.

[[einbindung-der-bibliothek-in-eine-anwendung]]
== Einbindung der Bibliothek in eine Anwendung

Um die Bibliothek in einer Anwendung nutzen zu können, sind zwei Schritte notwendig

* Integration mit Maven und
* Instanziierung der Transformator Factory.

[[integration-mit-maven]]
=== Integration mit Maven

In der POM der Anwendung muss die Abhängigkeit hinzugefügt werden:

[source,xml]
----
<dependency>
  <groupId>de.bund.bva.isyfact</groupId>
  <artifactId>isy-sonderzeichen</artifactId>
  <version><aktueller Version der Bibliothek></version>
</dependency>
----

[[instanziierung-der-transformator-factory]]
=== Instanziierung der Transformator Factory

Die Transformator-Factory und ein konkreter Transformator werden über Spring instanziiert.

[source,xml]
----
<bean id="sonderzeichenTransformatorFactory" class="de.bund.bva.pliscommon.plissonderzeichen.stringlatin1_1.core.transformation.TransformatorFactory">
  <property name="transformator" ref="sonderzeichenTransformator" >
  <property name="transformationsTabelle" + value="${Pfad_zu_einerzusaetzlichenTabelle}">
</bean>

<bean id="sonderzeichenTransformator" class="de.bund.bva.pliscommon.plissonderzeichen.stringlatin1_1.core.transformation.impl.IdentischerTransformator">
</bean>
----

In obigem Beispiel wird dabei der Transformator _IdentischerTransformator_ aus der ursprünglichen Umsetzung geladen.
Jeder der Transformatoren setzt bereits eine fest implementierte Transformationstabelle nach einem bestimmten
Vorgehen um (siehe <<funktionsweise>>).

Bei der Konfiguration der _TransformatorFactory_ kann die zusätzliche (optionale)
Eigenschaft _transformationsTabelle_ dazu genutzt werden, eine weitere Transformationstabelle anzugeben.
Die Regeln in dieser Tabelle überschreiben dabei existierende alte Regeln.
Es findet also eine Ergänzung der existierenden Regeln statt.

Das Vorgehen für die Komponenten der DIN Spezifikation 91 379 ist analog. Es müssen lediglich die Package-Pfade der Klassen aktualisiert werden.

[[schnittstellendefinition]]
== Schnittstellendefinition

Der Aufruf des Transformators erfolgt über die jeweilige Methode der Transformator Schnittstelle.
Folgende Methoden stehen zur Verfügung:

:desc-table-Transformator-Methoden: Transformator-Methoden
[id="table-Transformator-Methoden",reftext="{table-caption} {counter:tables}"]
.{desc-table-Transformator-Methoden}
[cols=",",options="header",]
|====
|Methode |Parameter
a|
`transformiere`

Transformiert eine Zeichenkette auf der Basis der zugrunde liegenden Transformationstabelle.

Leerzeichen am Anfang und am Ende der Zeichenkette werden entfernt.

Doppelte Leerzeichen innerhalb der Zeichenkette werden zu einem Leerzeichen umgewandelt.

 a|
`String zeichenkette`

Die zu transformierende Zeichenkette

a|
`transformiere`

Transformiert eine Zeichenkette analog der zuvor beschriebenen `transformiere`-Funktion.
Stellt zusätzlich sicher, dass die Zeichenkette nach der Operation die angegebene Länge hat.
Es wird dabei nicht unterschieden, ob die ursprüngliche Zeichenkettenlänge bereits das Maximum überschritten hat
oder erst durch eine Transformation die Zeichenkette verlängert wurde.

 a|
`String zeichenkette`

Die zu transformierende Zeichenkette

`int maximaleLaenge`

Die maximale Länge der Zeichenkette

a|
`transformiereOhneTrim`

Transformiert eine Zeichenkette analog der zuvor beschriebenen `transformiere`-Funktion.
Es werden jedoch keine Leerzeichen am Anfang/Ende der übergebenen Zeichenkette entfernt.

 a|
`String zeichenkette`

Die zu transformierende Zeichenkette

a|
`getRegulaererAusdruck`

Gibt den regulären Ausdruck zurück, der alle gültige Zeichenketten beschreibt, deren Zeichen in der jeweiligen
Zeichenkategorie aufgeführt sind.

 a|
`String[] kategorieListe`

Eine Liste mit den Zeichenkategorien.
Gültige Werte sind `LETTER, NUMBER, PUNCTUATION, SEPARATOR, SYMBOL, OTHER`.

Die Werte sind der Konstantenklasse `ZeichenKategorie` zu entnehmen.

a|
`getGueltigeZeichen`

Gibt alle gültigen Zeichen des Transformators zurück.

 a|
`String kategorie`

Eine Zeichenkategorie aus `LETTER, NUMBER, PUNCTUATION, SEPARATOR, SYMBOL, OTHER`.

|====

[underline]*Hinweis zur Funktion* [underline]`transformiere`

Die Transformationsfunktion arbeitet die Zeichenkette char für char ab.
Sollte ein Unicode-Character, welcher aus mehreren char Objekten besteht definiert sein (non-BMP
character, z.B. I mit angehängtem Circumflex (\\u006C\\u0302), so liefert die Transformationsfunktion
das korrekte Ergebnis, kann aber nicht zwischen String.Latin- und Nicht-String.Latin-Zeichen unterscheiden.
So könnten Zeichen außerhalb des Definitionsbereichs (z.B. alle \\u\####\\u0302) der Transformation
transformiert werden.

Zur Überprüfung ob eine Zeichenkette innerhalb des für den Transformator gültigen Bereichs liegt,
sollte daher die Funktion `getRegulaererAusdruck(String[])` benutzt werden um einen regulären Ausdruck für alle gültigen Zeichen zu erstellen.

[[zulaessige-zeichen-innerhalb-der-isyfact]]
= Zulässige Zeichen innerhalb der IsyFact

Die im Rahmen der IsyFact zugelassenen Zeichen gliedern sich in Standardzeichen und zusätzliche Zeichen.
Die Standardzeichen müssen von jeder Anwendung immer unterstützt werden.
Die zusätzlichen Zeichen müssen nur unterstützt werden, wenn dies entsprechend vereinbart wurde.
Die Festlegungen für die zulässigen Zeichen orientieren sich an den Festlegungen, die für das Meldewesen getroffen wurden.

Die für die IsyFact zulässigen Zeichen werden im Folgenden aufgeführt. (Siehe Kapitel
<<festlegung-des-zeichensatzes-und-der-codierung>>)

[[standardzeichen]]
== Standardzeichen

* Großbuchstaben: A-Z Ä Ö Ü
* Kleinbuchstaben: a-z ä ö ü ß
* Ziffern: 0-9
* **Sonderzeichen**: ' ( ) + , - . / Leerzeichen

[[zusaetzliche-zeichen]]
== Zusätzliche Zeichen

In <<table-zusaetzliche-zeichen>> sind die Zeichen dargestellt, die zusätzlich unterstützt werden.
Damit die Zeichen in der Spalte „Glyph“ korrekt dargestellt werden, muss ein Font installiert sein, der alle Zeichen
unterstützt. (z.B. Code2000, erhältlich unter http://www.code2000.net).
